{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cs684_project_DANN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/david-siqi-liu/cs684-final-project/blob/master/cs684_project_DANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrcyDifG2NsW",
        "colab_type": "text"
      },
      "source": [
        "# Preliminary Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vv1oFEAo15yy",
        "colab_type": "text"
      },
      "source": [
        "Naive, Pre-trained model, transfer learning:\n",
        "\n",
        "label : 10, epochs : 2, accu : 82.9% / 82.2% / 82.2%\n",
        "\n",
        "Transformations:\n",
        "\n",
        "Test: none\n",
        "Train (one at a time)  \n",
        "\n",
        "Center-crop\n",
        "\n",
        "\ttransforms.Resize([200, 200]\n",
        "\ttransforms.CenterCrop(50)  33% / 38% / 29%\n",
        "\n",
        "\ttransforms.Resize([200, 200]\n",
        "\ttransforms.CenterCrop(100) 67% / 70% / 65%\n",
        "\n",
        "\ttransforms.Resize([200, 200]\n",
        "\ttransforms.CenterCrop(150) 80% / 87% / 79%\n",
        "\t\n",
        "\ttransforms.CenterCrop(50)  41.03% / 17.77% / 29%\n",
        "\ttransforms.Resize([200, 200]\n",
        "\n",
        "\ttransforms.CenterCrop(100)  61.86% / 38.01% / 48.58%\n",
        "\ttransforms.Resize([200, 200]\n",
        "\n",
        "\ttransforms.CenterCrop(150)  75.60% / 53.31% / 57.62%\n",
        "\ttransforms.Resize([200, 200]\n",
        "\n",
        "Random-crop\n",
        "\n",
        "\ttransforms.Resize([200, 200]\n",
        "\ttransforms.RandomCrop(50)  53% / 26% / 27%\n",
        "\n",
        "\ttransforms.Resize([200, 200]\n",
        "\ttransforms.RandomCrop(100) 76% / 68% / 74%\n",
        "\n",
        "\ttransforms.Resize([200, 200]\n",
        "\ttransforms.RandomCrop(150) 82% / 81% / 81%\n",
        "\n",
        "Horizontal flips\n",
        "\n",
        "\ttransforms.RandomHorizontalFlip(p=0.5)\t77.31% / 81.97% / 86.98%\n",
        "\n",
        "Random rotation\n",
        "\n",
        "\ttransforms.RandomRotation(5)\t89%\t/ 87.93% / 88.25\n",
        "\n",
        "\ttransforms.RandomRotation(10)\t81.30% / 83.28% / 78.30%\n",
        "\n",
        "Horizontal&Vertical shifts\n",
        "\t\n",
        "\ttransforms.RandomAffine(0, translate=(0.05,0.05))  84.37% / 85.75% / 91.37%\n",
        "\n",
        "\ttransforms.RandomAffine(0, translate=(0.1,0.1))\t76.86% / 88.27% / 78.57%\t\n",
        "\n",
        "Color Jitter\n",
        "\t\n",
        "\ttransforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1)\t81.77% / 94.08% / 87.11%\n",
        "\n",
        "\ttransforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2)\t86.71% / 90.83% / 84.78%\n",
        "\n",
        "RandomAffineTransformation\n",
        "\n",
        "\ttransforms.RandomAffine(5, shear=10, scale=(0.8, 1.2))\t77.41% / 87.04% / 82.25%\n",
        "\n",
        "domain Comparison\n",
        "\n",
        "in case of domain comparison, I changed 'learning epochs' as 6 instead of 2 \n",
        "\n",
        "source = ['quickdraw']\n",
        "\n",
        "target = ['clipart']\n",
        "\n",
        "33.65% / 31.35% / 33.05%\n",
        "\n",
        "-------------------------\n",
        "source = ['real']\n",
        "\n",
        "target = ['clipart']\n",
        "\n",
        "77.23% / 70.52% / 77.39%\n",
        "\n",
        "-------------------------\n",
        "\n",
        "source = ['sketch']\n",
        "\n",
        "target = ['clipart']\n",
        "\n",
        "76.76% / 75.0% / 82.99%\n",
        "\n",
        "-------------------------\n",
        "\n",
        "\n",
        "source = ['quickdraw', 'real']\n",
        "\n",
        "target = ['clipart']\n",
        "\n",
        "84.41% / 63.90% / 71.75%\n",
        "\n",
        "-------------------------\n",
        "\n",
        "source = ['quickdraw', 'sketch']\n",
        "\n",
        "target = ['clipart']\n",
        "\n",
        "78.81% / 70.20% / 71.34%\n",
        "\n",
        "-------------------------\n",
        "\n",
        "source = ['real', 'sketch']\n",
        "\n",
        "target = ['clipart']\n",
        "\n",
        "85.94% / 85.64% / 86.72%\n",
        "\n",
        "-------------------------\n",
        "\n",
        "\n",
        "50 labels\n",
        "\n",
        "basic : 73.54% / 71.61% / 71.26%\n",
        "\n",
        "-------------------------\n",
        "\n",
        "source = ['quickdraw','real', 'sketch']\n",
        "target = ['clipart']\n",
        "transforms.RandomRotation(5),\n",
        "transforms.RandomAffine(0, translate=(0.05,0.05)),\n",
        "transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
        "\n",
        "10 labels : 83.37% / 78.93% / 74.21% \n",
        "\n",
        "-------------------------\n",
        "\n",
        "source = ['real', 'sketch']\n",
        "target = ['clipart']\n",
        "transforms.RandomRotation(5),\n",
        "transforms.RandomAffine(0, translate=(0.05,0.05)),\n",
        "transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
        "\n",
        "10 labels : 89.87% / 80.49% / 75.33% / 83.73% \n",
        "\n",
        "-------------------------\n",
        "\n",
        "50 labels : 70.64% \n",
        "\n",
        "-------------------------\n",
        "\n",
        "DANN Performance\n",
        "\n",
        "\n",
        "\n",
        "lr=0.00005 label 10 epochs 100 accuracy 57.78%\n",
        "lr=0.0001 label 10 epochs 100 accuracy 76.63%\n",
        "lr=0.0002 label 10 epochs 100 accuracy 67.07%\n",
        "lr=0.0005 label 10 epochs 100 accuracy 41.66%\n",
        "\n",
        "label 10 \n",
        "lr=0.0001 label 10 epochs 1 accuracy 64.34%\n",
        "lr=0.0001 label 10 epochs 2 accuracy 72.40%\n",
        "lr=0.0001 label 10 epochs 3 accuracy 80.05%\n",
        "lr=0.0001 label 10 epochs 4 accuracy 85.51% / 85.51% / 86.06 / 85.24%\n",
        "lr=0.0001 label 10 epochs 5 accuracy 78.14% / 78.82% / 79.91% / 81.14%\n",
        "lr=0.0001 label 10 epochs 6 accuracy 80.87%\n",
        "lr=0.0001 label 10 epochs 7 accuracy 86.47% / 84.42 / 82.10 %\n",
        "lr=0.0001 label 10 epochs 8 accuracy 83.46%\n",
        "lr=0.0001 label 10 epochs 9 accuracy 81.55%\n",
        "lr=0.0001 label 10 epochs 10 accuracy 84.28%\n",
        "lr=0.0001 label 10 epochs 20 accuracy 82.14%\n",
        "\n",
        "label 50\n",
        "\n",
        "lr=0.0001 label 50 epochs 1 accuracy 38.28%\n",
        "lr=0.0001 label 50 epochs 2 accuracy 41.82%\n",
        "lr=0.0001 label 50 epochs 4 accuracy 40.98%\n",
        "lr=0.0001 label 50 epochs 8 accuracy 40.98%\n",
        "lr=0.0001 label 50 epochs 50 accuracy 57.01%\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aB47iAzbsxx_",
        "colab_type": "text"
      },
      "source": [
        "# Download Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6We2S3VR8td",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf sample_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A0vnybQBrDzV",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "from urllib.request import urlretrieve\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "\n",
        "def download(url, file):\n",
        "    if not os.path.isfile(file):\n",
        "        urlretrieve(url, file)\n",
        "\n",
        "#If the downloaded file is a zip file than you can use below function to unzip it.\n",
        "def uncompress_features_labels(source, file, dest):\n",
        "    if not os.path.isdir(file):\n",
        "        with ZipFile(source) as zipf:\n",
        "            zipf.extractall(dest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtQWsgY9fQDD",
        "colab_type": "text"
      },
      "source": [
        "'clipart.zip', 'infograph.zip', 'quickdraw.zip', 'real.zip', 'sketch.zip'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ArnoEFEqaoST",
        "colab": {}
      },
      "source": [
        "# Source images\n",
        "for file in ['infograph.zip', 'quickdraw.zip', 'real.zip', 'sketch.zip']:\n",
        "  download('http://csr.bu.edu/ftp/visda/2019/multi-source/' + file,\n",
        "           file)\n",
        "  print(\"Downloaded: {0}\".format(file))\n",
        "  uncompress_features_labels(file,\n",
        "                             'data/' + file.split('.zip')[0],\n",
        "                             'data/')\n",
        "  print(\"Extracted: {0}\".format(file))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00n-01_7o7yJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Target images (labelled)\n",
        "download('http://csr.bu.edu/ftp/visda/2019/multi-source/groundtruth/clipart.zip', 'clipart.zip')\n",
        "print(\"Downloaded: clipart.zip\")\n",
        "uncompress_features_labels('clipart.zip', 'data/clipart', 'data/')\n",
        "print(\"Extracted: clipart.zip\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PD61CFtjVQQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyC2khchRv5z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Source labels\n",
        "for file in ['infograph', 'quickdraw', 'real', 'sketch']:\n",
        "  download('http://csr.bu.edu/ftp/visda/2019/multi-source/txt/' + file + '_train.txt',\n",
        "           'label/' + file + '_train.txt')\n",
        "  download('http://csr.bu.edu/ftp/visda/2019/multi-source/txt/' + file + '_test.txt',\n",
        "           'label/' + file + '_test.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16Olz1oRowml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Target labels (groundtruth)\n",
        "# For the training set, we will NOT look at their labels, so it's still unsupervised\n",
        "download('http://csr.bu.edu/ftp/visda/2019/multi-source/groundtruth/txt/clipart_train.txt',\n",
        "           'label/clipart_train.txt')\n",
        "download('http://csr.bu.edu/ftp/visda/2019/multi-source/groundtruth/txt/clipart_test.txt',\n",
        "           'label/clipart_test.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfrwl2Wrs9wN",
        "colab_type": "text"
      },
      "source": [
        "# Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLZKatCYs_Iv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.autograd import Variable\n",
        "from torch.autograd import Function\n",
        "from PIL import Image, ImageColor\n",
        "import os\n",
        "import random\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from time import time\n",
        "import pylab as pl\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import offsetbox\n",
        "from sklearn import (manifold, datasets, decomposition, ensemble,\n",
        "                     discriminant_analysis, random_projection, neighbors)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import torchvision.models as models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JASZ-NKKLBwL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "USE_GPU = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpaFroT8SVFs",
        "colab_type": "text"
      },
      "source": [
        "# Load Images and Labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6h-ZkJcgsak2",
        "colab_type": "text"
      },
      "source": [
        "In total there are 345 labels. For this project, we'll downsize this to only 10 labels. For simplicity, we'll use the first 10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQb8yhWvsxQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_labels = 8\n",
        "\n",
        "# Seed\n",
        "manual_seed = 647\n",
        "random.seed(manual_seed)\n",
        "torch.manual_seed(manual_seed)\n",
        "\n",
        "# Randomly select labels\n",
        "selected_original_labels = random.sample(range(344), num_labels)\n",
        "selected_original_labels.sort()\n",
        "\n",
        "print(\"Selected labels: {0}\".format(selected_original_labels))\n",
        "\n",
        "# Create label mapping\n",
        "label_to_original_mapping = {}\n",
        "for i in range(0, num_labels):\n",
        "  label_to_original_mapping[i] = selected_original_labels[i]\n",
        "  \n",
        "original_to_label_mapping = {v : k for k, v in label_to_original_mapping.items()}\n",
        "print(\"Original to label mapping: {0}\".format(original_to_label_mapping))\n",
        "print(\"Label to original mapping: {0}\".format(label_to_original_mapping))\n",
        "\n",
        "# Find English term in target test file (since it's the smallest to load)\n",
        "original_to_english_mapping = {}\n",
        "for line in open(\"label/clipart_test.txt\"):\n",
        "  d = line.strip().split(' ')\n",
        "  l = int(d[1])\n",
        "  original_to_english_mapping[l] = d[0].split(\"/\")[1]\n",
        "  \n",
        "print(\"Original to English mapping: {0}\".format(original_to_english_mapping))\n",
        "\n",
        "# Final label mapping\n",
        "labels = {}\n",
        "for i in range(0, num_labels):\n",
        "  labels[i] = original_to_english_mapping[label_to_original_mapping[i]]\n",
        "\n",
        "print(\"Labels: {0}\".format(labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWWPwxiD-f56",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###### LIST LOADER #######\n",
        "\n",
        "def default_loader(path):\n",
        "    \"\"\"Default loader\n",
        "    \"\"\"\n",
        "    return Image.open(path).convert('RGB')\n",
        "\n",
        "def collect_images(img_dir, labels):\n",
        "  \"\"\"Return a list of (image path, label)\n",
        "\n",
        "  Parameters:\n",
        "  img_dir (String) : the directory containing the images\n",
        "  labels (List[String]) : a list of labels (merged multiple sources together)\n",
        "\n",
        "  Returns:\n",
        "  List[(String, String)]\n",
        "  \"\"\"\n",
        "  images = []\n",
        "  indices = {}\n",
        "  pos = 0\n",
        "  for line in labels:\n",
        "    data = line.strip().split(' ')\n",
        "    path = os.path.join(img_dir, data[0])\n",
        "    original_label = int(data[1])\n",
        "    domain = int(data[2])\n",
        "    # Among the labels selected\n",
        "    if original_label in selected_original_labels:\n",
        "      label = original_to_label_mapping[original_label]\n",
        "      item = (path, label, domain)\n",
        "      images.append(item)\n",
        "      if label not in indices.keys():\n",
        "        indices[label] = [pos]\n",
        "      else:\n",
        "        indices[label].append(pos)\n",
        "      pos += 1\n",
        "  return images, indices\n",
        "\n",
        "class MyDataset(data.Dataset):\n",
        "    \"\"\" Custom class for loading image list\n",
        "    \"\"\"\n",
        "    def __init__(self, img_dir, labels, transform=None, loader=default_loader):\n",
        "        imgs, indices = collect_images(img_dir, labels)\n",
        "        self.img_dir = img_dir\n",
        "        self.imgs = imgs\n",
        "        self.indices = indices\n",
        "        self.num_imgs = len(imgs)\n",
        "        self.transform = transform\n",
        "        self.loader = loader\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        path, label, domain = self.imgs[index]\n",
        "        img = self.loader(path)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "            \n",
        "        return img, label, domain\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "\n",
        "    def get_random_sample_index(self, label, n=1):\n",
        "      return np.random.choice(self.indices[label], n)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kg1bK1ZdeZFf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###### IMAGE LOADER #######\n",
        "\n",
        "batch_size_train = 56\n",
        "batch_size_test = 24\n",
        "\n",
        "def make_data_set(img_dir, label_dir, domain_list, transforms, source_or_target, train_or_test):\n",
        "  labels = []\n",
        "  if (source_or_target == 'source'):\n",
        "    for d in range(len(domain_list)):\n",
        "      # E.g. \"label/infograph_test.txt\"\n",
        "      label_file = label_dir + domain_list[d] + '_' + train_or_test + '.txt'\n",
        "      for line in open(label_file):\n",
        "        # Space delimited\n",
        "        # Source domain starts at 1\n",
        "        labels.append(line + \" {0}\".format(d + 1))\n",
        "  else:\n",
        "    # E.g. \"label/clipart_test.txt\"\n",
        "    label_file = label_dir + domain_list[0] + '_' + train_or_test + '.txt'\n",
        "    for line in open(label_file):\n",
        "        # Space delimited\n",
        "        # Target domain is always 0\n",
        "        labels.append(line + \" 0\")\n",
        "  return MyDataset(img_dir, labels, transforms)\n",
        "\n",
        "def make_data_loader(dataset, train_or_test):\n",
        "  if (train_or_test == 'train'):\n",
        "    return data.DataLoader(dataset, batch_size=batch_size_train,\n",
        "                           shuffle=True, num_workers=4)\n",
        "  else:\n",
        "    return data.DataLoader(dataset, batch_size=batch_size_test,\n",
        "                           shuffle=True, num_workers=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTZCVY8euMeq",
        "colab_type": "text"
      },
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubNqS8aRbIso",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "norm = ([0.485, 0.456, 0.406],\n",
        "        [0.229, 0.224, 0.225])\n",
        "\n",
        "def tensor_to_PIL(img, mean, std):\n",
        "  img = img.numpy().transpose((1, 2, 0))\n",
        "  img = img * std + mean\n",
        "  img = np.clip(img, 0, 1)\n",
        "  return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEVTjIIdIWH5",
        "colab_type": "text"
      },
      "source": [
        "# Model Evaluation Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EGmaNTKIa4D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def confusion_matrix(preds, targets, conf_matrix):\n",
        "    preds = torch.argmax(preds, 1)\n",
        "    for p, t in zip(preds, targets):\n",
        "        conf_matrix[p, t] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJIncnhtO73o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Scale and visualize the embedding vectors\n",
        "def plot_embedding(X, title=None):\n",
        "\n",
        "    digits = datasets.load_digits(n_class=num_labels)\n",
        "\n",
        "    x_min, x_max = np.min(X, 0), np.max(X, 0)\n",
        "    X = (X - x_min) / (x_max - x_min)\n",
        "\n",
        "    pl.figure()\n",
        "    ax = pl.subplot(111)\n",
        "    for i in range(X.shape[0]):\n",
        "        pl.text(X[i, 0], X[i, 1], str(digits.target[i]),\n",
        "                color=pl.cm.Set1(y[i] / 10.),\n",
        "                fontdict={'weight': 'bold', 'size': 9})\n",
        "\n",
        "    if hasattr(offsetbox, 'AnnotationBbox'):\n",
        "        # only print thumbnails with matplotlib > 1.0\n",
        "        shown_images = np.array([[1., 1.]])  # just something big\n",
        "        for i in range(np.shape(X)[0]):\n",
        "            dist = np.sum((X[i] - shown_images) ** 2, 1)\n",
        "            if np.min(dist) < 4e-3:\n",
        "                # don't show points that are too close\n",
        "                continue\n",
        "            shown_images = np.r_[shown_images, [X[i]]]\n",
        "            imagebox = offsetbox.AnnotationBbox(\n",
        "                offsetbox.OffsetImage(digits.images[i], cmap=pl.cm.gray_r),\n",
        "                X[i])\n",
        "            ax.add_artist(imagebox)\n",
        "    pl.xticks([]), pl.yticks([])\n",
        "    if title is not None:\n",
        "        pl.title(title)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPhw9kOrIeu4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validate(val_loader, net, vis=True):\n",
        "  \n",
        "    conf_matrix = torch.zeros(num_labels, num_labels)\n",
        "    net.eval()\n",
        "    val_loss = 0\n",
        "    correct = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(val_loader):\n",
        "            \n",
        "            inputs, target, domain = data\n",
        "\n",
        "            if USE_GPU:\n",
        "                inputs = inputs.cuda()\n",
        "                target = target.cuda()\n",
        "                domain = domain.cuda()\n",
        "                net = net.cuda()\n",
        "\n",
        "            output = net(inputs)[0]\n",
        "\n",
        "            val_loss += F.nll_loss(output, target, reduction='mean').item()\n",
        "\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            \n",
        "            confusion_matrix(output, target, conf_matrix)\n",
        "   \n",
        "    val_loss /= len(val_loader.dataset)\n",
        "\n",
        "\n",
        "    if vis:\n",
        "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "            val_loss, correct, len(val_loader.dataset),\n",
        "           # float((num_labels ** 2) * correct / len(val_loader.dataset))))\n",
        "            100. * correct / len(val_loader.dataset)))\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.imshow(conf_matrix, cmap='viridis', interpolation='nearest')\n",
        "        plt.colorbar()\n",
        "        plt.xticks(np.arange(num_labels), labels.values(), rotation='vertical')\n",
        "        plt.yticks(np.arange(num_labels), labels.values())\n",
        "        plt.show()\n",
        "        \n",
        "    net.train()\n",
        "    return correct / len(val_loader.dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anueoh5hBR1A",
        "colab_type": "text"
      },
      "source": [
        "# Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ag9BY8ncwFvc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "home_dir = ''\n",
        "img_dir = home_dir + 'data/'\n",
        "label_dir = home_dir + 'label/'\n",
        "\n",
        "source = ['quickdraw', 'real', 'sketch']\n",
        "target = ['clipart']\n",
        "num_source_domains = len(source)\n",
        "\n",
        "img_size = 224"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMLPfynFwKkI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "source_train_transforms = transforms.Compose([transforms.Resize([img_size, img_size]),\n",
        "                                              transforms.ToTensor(),\n",
        "                                              transforms.Normalize(*norm)])\n",
        "\n",
        "source_test_transforms = transforms.Compose([transforms.Resize([img_size, img_size]),\n",
        "                                             transforms.ToTensor(),\n",
        "                                             transforms.Normalize(*norm)])\n",
        "\n",
        "target_train_transforms = transforms.Compose([transforms.Resize([img_size, img_size]),\n",
        "                                              transforms.ToTensor(),\n",
        "                                              transforms.Normalize(*norm)])\n",
        "\n",
        "target_test_transforms = transforms.Compose([transforms.Resize([img_size, img_size]),\n",
        "                                             transforms.ToTensor(),\n",
        "                                             transforms.Normalize(*norm)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTqFWtAtV3On",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "source_train_dataset = make_data_set(img_dir, label_dir, source, source_train_transforms, 'source', 'train')\n",
        "source_train_dataloader = make_data_loader(source_train_dataset, 'train')\n",
        "\n",
        "source_test_dataset = make_data_set(img_dir, label_dir, source, source_test_transforms, 'source', 'test')\n",
        "source_test_dataloader = make_data_loader(source_test_dataset, 'test')\n",
        "\n",
        "target_train_dataset = make_data_set(img_dir, label_dir, target, target_train_transforms, 'target', 'train')\n",
        "target_train_dataloader = make_data_loader(target_train_dataset, 'train')\n",
        "\n",
        "target_test_dataset = make_data_set(img_dir, label_dir, target, target_test_transforms, 'target', 'test')\n",
        "target_test_dataloader = make_data_loader(target_test_dataset, 'test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9bPf-ivtyE0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Source train dataset size: {0}\".format(len(source_train_dataset)))\n",
        "print(\"Source test dataset size: {0}\".format(len(source_test_dataset)))\n",
        "print(\"Target train dataset size: {0}\".format(len(target_train_dataset)))\n",
        "print(\"Target test dataset size: {0}\".format(len(target_test_dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iN-Zwk45we3P",
        "colab_type": "text"
      },
      "source": [
        "# Sample Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95QKQYNMqARJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(15, 15))\n",
        "\n",
        "plt.subplots_adjust(hspace=0.5)\n",
        "\n",
        "for label, english in enumerate(labels.values()):\n",
        "  index = source_train_dataset.get_random_sample_index(label)\n",
        "  img, _, domain = source_train_dataset[index]\n",
        "  ax1 = fig.add_subplot(num_labels/4+1, 4, label+1)\n",
        "  plt.title(\"{0} : {1} : {2}\".format(source[domain - 1], label, english))\n",
        "  ax1.imshow(tensor_to_PIL(img, *norm))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKo_b_pMq7Kr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(15, 15))\n",
        "\n",
        "plt.subplots_adjust(hspace=0.5)\n",
        "\n",
        "for label, english in enumerate(labels.values()):\n",
        "  index = source_test_dataset.get_random_sample_index(label)\n",
        "  img, _, domain = source_test_dataset[index]\n",
        "  ax1 = fig.add_subplot(num_labels/4+1, 4, label+1)\n",
        "  plt.title(\"{0} : {1} : {2}\".format(source[domain - 1], label, english))\n",
        "  ax1.imshow(tensor_to_PIL(img, *norm))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrEZ0UFEq9-_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(15, 15))\n",
        "\n",
        "plt.subplots_adjust(hspace=0.5)\n",
        "\n",
        "for label, english in enumerate(labels.values()):\n",
        "  index = target_train_dataset.get_random_sample_index(label)\n",
        "  img, _, domain = target_train_dataset[index]\n",
        "  ax1 = fig.add_subplot(num_labels/4+1, 4, label+1)\n",
        "  plt.title(\"{0} : {1} : {2}\".format(target[domain], label, english))\n",
        "  ax1.imshow(tensor_to_PIL(img, *norm))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0MOfDNAwn9i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(15, 15))\n",
        "\n",
        "plt.subplots_adjust(hspace=0.5)\n",
        "\n",
        "for label, english in enumerate(labels.values()):\n",
        "  index = target_test_dataset.get_random_sample_index(label)\n",
        "  img, _, domain = target_test_dataset[index]\n",
        "  ax1 = fig.add_subplot(num_labels/4+1, 4, label+1)\n",
        "  plt.title(\"{0} : {1} : {2}\".format(target[domain], label, english))\n",
        "  ax1.imshow(tensor_to_PIL(img, *norm))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3VPudTswqpN",
        "colab_type": "text"
      },
      "source": [
        "# DANN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLoFOe2gwwaH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ReverseLayerF(Function):\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, alpha):\n",
        "        # Store context for backward propagation\n",
        "        ctx.alpha = alpha\n",
        "\n",
        "        # Do nothing in forward pass\n",
        "        return x.view_as(x)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        # Baskward pass is just to reverse (-alpha) the gradient\n",
        "        output = grad_output.neg() * ctx.alpha\n",
        "\n",
        "        # Must return same number as inputs to forward()\n",
        "        return output, None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsxYhAfB2jHE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "debug = False\n",
        "\n",
        "class DANN(nn.Module):\n",
        "    def __init__(self, num_labels, num_source_domains):\n",
        "        super(DANN, self).__init__()\n",
        "\n",
        "        # Download pre-trained ResNet50\n",
        "        resnet = models.resnet50(pretrained = True)\n",
        "\n",
        "        ### Feature learning\n",
        "        # Base layers\n",
        "        self.conv1 = resnet.conv1\n",
        "        self.bn1 = resnet.bn1\n",
        "        # ResNet layers\n",
        "        self.res1 = resnet.layer1\n",
        "        self.res2 = resnet.layer2\n",
        "        self.res3 = resnet.layer3\n",
        "        self.res4 = resnet.layer4\n",
        "        # Average Pool\n",
        "        self.avgpool = resnet.avgpool\n",
        "\n",
        "        ### Class classifier\n",
        "        self.class_fc1 = nn.Linear(2048, 100)\n",
        "        self.class_bn1 = nn.BatchNorm1d(100)\n",
        "        self.class_fc2 = nn.Linear(100, num_labels)\n",
        "\n",
        "        ### Domain classifier\n",
        "        self.domain_fc1 = nn.Linear(2048, 100)\n",
        "        self.domain_bn1 = nn.BatchNorm1d(100)\n",
        "        self.domain_fc2 = nn.Linear(100, num_source_domains + 1)\n",
        "        \n",
        "    def forward(self, x, alpha=1.0):\n",
        "        ### Feature learning\n",
        "        # Base layer\n",
        "        if debug: print(\"--START ENCODING\")\n",
        "        if debug: print(\"Input shape: {0}\".format(x.shape))\n",
        "        feature = self.conv1(x)\n",
        "        if debug: print(\"After conv1: {0}\".format(feature.shape))\n",
        "        feature = self.bn1(feature)\n",
        "        if debug: print(\"After bn1: {0}\".format(feature.shape))\n",
        "        feature = F.relu(feature)\n",
        "        feature = F.max_pool2d(feature, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
        "        if debug: print(\"After base layer: {0}\".format(feature.shape))\n",
        "        # ResNet layers\n",
        "        feature = self.res1(feature)\n",
        "        if debug: print(\"After res1: {0}\".format(feature.shape))\n",
        "        feature = self.res2(feature)\n",
        "        if debug: print(\"After res2: {0}\".format(feature.shape))\n",
        "        feature = self.res3(feature)\n",
        "        if debug: print(\"After res3: {0}\".format(feature.shape))\n",
        "        feature = self.res4(feature)\n",
        "        if debug: print(\"After res4: {0}\".format(feature.shape))\n",
        "        feature = self.avgpool(feature)\n",
        "        if debug: print(\"After AdaptiveAvgPool: {0}\".format(feature.shape))\n",
        "        feature = torch.flatten(feature, 1)\n",
        "        if debug: print(\"Final feature: {0}\".format(feature.shape))\n",
        "\n",
        "        ### Class classifier\n",
        "        class_output = self.class_fc1(feature)\n",
        "        if debug: print(\"After fc1: {0}\".format(class_output.shape))\n",
        "        class_output = self.class_bn1(class_output)\n",
        "        if debug: print(\"After bn1: {0}\".format(class_output.shape))\n",
        "        class_output = F.relu(class_output)\n",
        "        class_output = self.class_fc2(class_output)\n",
        "        if debug: print(\"After fc2: {0}\".format(class_output.shape))\n",
        "        class_output = F.log_softmax(class_output, dim=1)\n",
        "        if debug: print(\"Final class classifier: {0}\".format(class_output.shape))\n",
        "\n",
        "        ### Domain classifier\n",
        "        # Gradient reversal layer\n",
        "        reverse_feature = ReverseLayerF.apply(feature, alpha)\n",
        "        domain_output = self.domain_fc1(reverse_feature)\n",
        "        if debug: print(\"After fc1: {0}\".format(domain_output.shape))\n",
        "        domain_output = self.domain_bn1(domain_output)\n",
        "        if debug: print(\"After bn1: {0}\".format(domain_output.shape))\n",
        "        domain_output = F.relu(domain_output)\n",
        "        domain_output = self.domain_fc2(domain_output)\n",
        "        if debug: print(\"After fc2: {0}\".format(domain_output.shape))\n",
        "        domain_output = F.log_softmax(domain_output, dim=1)\n",
        "        if debug: print(\"Final domain classifier: {0}\".format(domain_output.shape))\n",
        "\n",
        "        return class_output, domain_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIA06pvPzMBZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialie model\n",
        "model = DANN(num_labels, num_source_domains)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1JzU9EYzkY4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check\n",
        "x0_s, y0_s, d0_s = next(iter(source_train_dataloader))\n",
        "x0_t, y0_t, d0_t = next(iter(target_train_dataloader))\n",
        "\n",
        "#print('source domain: ', x0_s.shape, y0_s.shape, d0_s)\n",
        "#print('target domain: ', x0_t.shape, y0_t.shape, d0_t)\n",
        "\n",
        "model(x0_s)\n",
        "model(x0_t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqAQBTri0cpN",
        "colab_type": "text"
      },
      "source": [
        "# Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbbSR1LS0b0n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(),\n",
        "                             lr = 0.001)\n",
        "\n",
        "loss_class = torch.nn.NLLLoss()\n",
        "loss_domain = torch.nn.NLLLoss()\n",
        "\n",
        "if USE_GPU:\n",
        "    model = model.cuda()\n",
        "    loss_class = loss_class.cuda()\n",
        "    loss_domain = loss_domain.cuda()\n",
        "\n",
        "for p in model.parameters():\n",
        "    p.requires_grad = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SplukYi05Gx",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoPYfSNq07Tz",
        "colab_type": "code",
        "outputId": "fb06c379-ce20-49cc-9ab5-7d9bb8367e54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "n_epoch = 4\n",
        "\n",
        "# Train the same number of batches from both source and target\n",
        "max_batches = min(len(source_train_dataloader), len(target_train_dataloader))\n",
        "\n",
        "# Train\n",
        "for epoch_idx in range(n_epoch):\n",
        "    print(\"Epoch {0} / {1}\".format(epoch_idx + 1, n_epoch))\n",
        "    \n",
        "    source_data_iter = iter(source_train_dataloader)\n",
        "    target_data_iter = iter(target_train_dataloader)\n",
        "\n",
        "    for batch_idx in range(max_batches):\n",
        "        # Reset optimizer's gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Training progress\n",
        "        p = float(batch_idx + epoch_idx * max_batches) / (n_epoch * max_batches)\n",
        "\n",
        "        # Alpha for this batch\n",
        "        alpha = 2. / (1. + np.exp(-10 * p)) - 1\n",
        "\n",
        "        ### Source\n",
        "\n",
        "        # Get source images, labels and domains\n",
        "        s_img, s_label, s_domain = next(source_data_iter)\n",
        "\n",
        "        if USE_GPU:\n",
        "            s_img = s_img.cuda()\n",
        "            s_label = s_label.cuda()\n",
        "            s_domain = s_domain.cuda()\n",
        "\n",
        "        # Forward pass\n",
        "        label_pred, domain_pred = model(s_img, alpha)\n",
        "\n",
        "        # Compute losses\n",
        "        loss_s_label = loss_class(label_pred, s_label)\n",
        "        loss_s_domain = loss_domain(domain_pred, s_domain)\n",
        "\n",
        "        ### Target\n",
        "\n",
        "        # Training on target domain\n",
        "        # We don't compute the loss on label predictions\n",
        "        t_img, _ , t_domain = next(target_data_iter)\n",
        "\n",
        "        if USE_GPU:\n",
        "            t_img = t_img.cuda()\n",
        "            t_domain = t_domain.cuda()\n",
        "\n",
        "        # Forward pass\n",
        "        _, domain_pred = model(t_img, alpha)\n",
        "\n",
        "        # Compute loss\n",
        "        loss_t_domain = loss_domain(domain_pred, t_domain)\n",
        "\n",
        "        ### Combined\n",
        "        loss = loss_s_label + loss_s_domain + loss_t_domain\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        print (\"\\r\",'[%d / %d], loss_s_label: %04.4f, loss_s_domain: %04.4f, loss_t_domain: %04.4f, alpha: %04.4f' \\\n",
        "              % (batch_idx + 1, max_batches, loss_s_label.data.cpu().numpy(),\n",
        "                 loss_s_domain.data.cpu().numpy(), loss_t_domain.data.cpu().numpy(),\n",
        "                 alpha),end=\"\")\n",
        "        \n",
        "    print(' ')\n",
        "    \n",
        "    # torch.save({'state_dict': model.state_dict()}, '{0}/model_{1}.pth'.format(model_root, epoch_idx))\n",
        "\n",
        "    # test(source_dataset_name, epoch)\n",
        "    # test(target_dataset_name, epoch)\n",
        "\n",
        "print('done')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [90 / 90], loss_s_label: 2.9207, loss_s_domain: 1.7297, loss_t_domain: 0.6907, alpha: 0.0986 \n",
            "Epoch 2 / 50\n",
            " [90 / 90], loss_s_label: 2.5514, loss_s_domain: 1.8030, loss_t_domain: 0.6848, alpha: 0.1963 \n",
            "Epoch 3 / 50\n",
            " [90 / 90], loss_s_label: 2.1789, loss_s_domain: 1.8050, loss_t_domain: 0.7089, alpha: 0.2903 \n",
            "Epoch 4 / 50\n",
            " [90 / 90], loss_s_label: 2.3038, loss_s_domain: 1.7547, loss_t_domain: 0.6881, alpha: 0.3790 \n",
            "Epoch 5 / 50\n",
            " [45 / 90], loss_s_label: 2.4215, loss_s_domain: 1.7294, loss_t_domain: 0.7200, alpha: 0.4210"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuIQAHNANVJk",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFc29UfkNx0s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validate(target_train_dataloader, model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvQ0bv-6Ne8e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Change to evaluation mode\n",
        "model = model.eval()\n",
        "\n",
        "fig = plt.figure(figsize=(15, 15))\n",
        "\n",
        "plt.subplots_adjust(hspace=0.5)\n",
        "\n",
        "for label, english in enumerate(labels.values()):\n",
        "  index = target_test_dataset.get_random_sample_index(label)\n",
        "  img, _, domain = target_test_dataset[index]\n",
        "  if USE_GPU:\n",
        "      img = img.cuda()\n",
        "      model = model.cuda()\n",
        "\n",
        "  output = model.forward(img[None])[0]\n",
        "\n",
        "  prediction = int(torch.argmax(output).cpu().numpy())\n",
        "\n",
        "  ax1 = fig.add_subplot(num_labels/4+1, 4, label+1)\n",
        "  plt.title(\"Prediction: {0} \\n Ground Truth: {1}\".format(labels[prediction], labels[label]))\n",
        "  ax1.imshow(tensor_to_PIL(img.cpu(), *norm))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Hte4witEWsz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "leng = len(target_test_dataset)\n",
        "print(leng)\n",
        "#test_leng = 10\n",
        "\n",
        "imgs = np.zeros(shape=(leng,150528))\n",
        "labels = []\n",
        "    \n",
        "for index in range(0,leng) :\n",
        "    img, label, domain = target_test_dataset[index]\n",
        "    img = tensor_to_PIL(img, *norm)\n",
        "    img = img.flatten()\n",
        "    imgs[index] = img\n",
        "    labels.append(label)\n",
        "\n",
        "X = imgs\n",
        "y = labels\n",
        "\n",
        "\n",
        "print(\"Computing t-SNE embedding\")\n",
        "tsne = manifold.TSNE(perplexity=10, n_components=2, init='pca', learning_rate=200, random_state=0, n_iter=5000)\n",
        "t0 = time()\n",
        "X_tsne = tsne.fit_transform(X)\n",
        "plot_embedding(X_tsne,\n",
        "                \"t-SNE embedding of the digits (time %.2fs)\" %\n",
        "                (time() - t0))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dw7wvrO__hA9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Isomap projection of the digits dataset\n",
        "n_neighbors = 30\n",
        "\n",
        "print(\"Computing Isomap embedding\")\n",
        "t0 = time()\n",
        "X_iso = manifold.Isomap(n_neighbors, n_components=2).fit_transform(X)\n",
        "print(\"Done.\")\n",
        "plot_embedding(X_iso,\n",
        "               \"Isomap projection of the digits (time %.2fs)\" %\n",
        "               (time() - t0))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "af8WGIv_849M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Locally linear embedding of the digits dataset\n",
        "print(\"Computing LLE embedding\")\n",
        "clf = manifold.LocallyLinearEmbedding(n_neighbors, n_components=2,\n",
        "                                      method='standard')\n",
        "t0 = time()\n",
        "X_lle = clf.fit_transform(X)\n",
        "print(\"Done. Reconstruction error: %g\" % clf.reconstruction_error_)\n",
        "plot_embedding(X_lle,\n",
        "               \"Locally Linear Embedding of the digits (time %.2fs)\" %\n",
        "               (time() - t0))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZ_CDeoX889w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Modified Locally linear embedding of the digits dataset\n",
        "print(\"Computing modified LLE embedding\")\n",
        "clf = manifold.LocallyLinearEmbedding(n_neighbors, n_components=2,\n",
        "                                      method='modified')\n",
        "t0 = time()\n",
        "X_mlle = clf.fit_transform(X)\n",
        "print(\"Done. Reconstruction error: %g\" % clf.reconstruction_error_)\n",
        "plot_embedding(X_mlle,\n",
        "               \"Modified Locally Linear Embedding of the digits (time %.2fs)\" %\n",
        "               (time() - t0))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5IATqsf9G3P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MDS  embedding of the digits dataset\n",
        "print(\"Computing MDS embedding\")\n",
        "clf = manifold.MDS(n_components=2, n_init=1, max_iter=100)\n",
        "t0 = time()\n",
        "X_mds = clf.fit_transform(X)\n",
        "print(\"Done. Stress: %f\" % clf.stress_)\n",
        "plot_embedding(X_mds,\n",
        "               \"MDS embedding of the digits (time %.2fs)\" %\n",
        "               (time() - t0))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDlvvwb99JBE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Random Trees embedding of the digits dataset\n",
        "print(\"Computing Totally Random Trees embedding\")\n",
        "hasher = ensemble.RandomTreesEmbedding(n_estimators=200, random_state=0,\n",
        "                                       max_depth=5)\n",
        "t0 = time()\n",
        "X_transformed = hasher.fit_transform(X)\n",
        "pca = decomposition.TruncatedSVD(n_components=2)\n",
        "X_reduced = pca.fit_transform(X_transformed)\n",
        "\n",
        "plot_embedding(X_reduced,\n",
        "               \"Random forest embedding of the digits (time %.2fs)\" %\n",
        "               (time() - t0))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjLTmw8S9STi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Spectral embedding of the digits dataset\n",
        "print(\"Computing Spectral embedding\")\n",
        "embedder = manifold.SpectralEmbedding(n_components=2, random_state=0,\n",
        "                                      eigen_solver=\"arpack\")\n",
        "t0 = time()\n",
        "X_se = embedder.fit_transform(X)\n",
        "\n",
        "plot_embedding(X_se,\n",
        "               \"Spectral embedding of the digits (time %.2fs)\" %\n",
        "               (time() - t0))\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWeAch3M9Uo2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NCA projection of the digits dataset\n",
        "print(\"Computing NCA projection\")\n",
        "nca = neighbors.NeighborhoodComponentsAnalysis(init='random',\n",
        "                                               n_components=2, random_state=0)\n",
        "t0 = time()\n",
        "X_nca = nca.fit_transform(X, y)\n",
        "\n",
        "plot_embedding(X_nca,\n",
        "               \"NCA embedding of the digits (time %.2fs)\" %\n",
        "               (time() - t0))\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}