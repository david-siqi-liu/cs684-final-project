{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DANN_Colab_CPU_Project_14Dec_21:34.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/david-siqi-liu/cs684-final-project/blob/master/DANN_Colab_CPU_Project_14Dec_21_34.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9o7lCpk7nxX",
        "colab_type": "text"
      },
      "source": [
        "# Data Download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kCLvchwPY_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Project\n",
        "\n",
        "from urllib.request import urlretrieve\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "\n",
        "def download(url, file):\n",
        "    if not os.path.isfile(file):\n",
        "        urlretrieve(url, file)\n",
        "\n",
        "#If the downloaded file is a zip file than you can use below function to unzip it.\n",
        "def uncompress_features_labels(source, file, dest):\n",
        "    if not os.path.isdir(file):\n",
        "        with ZipFile(source) as zipf:\n",
        "            zipf.extractall(dest)\n",
        "\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48bKmcf9P57f",
        "colab_type": "code",
        "outputId": "11d12e70-57c2-4c36-e6a5-a4883d81b0fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "# Project\n",
        "# Source images\n",
        "for file in ['infograph.zip', 'quickdraw.zip', 'real.zip', 'sketch.zip']:\n",
        "  download('http://csr.bu.edu/ftp/visda/2019/multi-source/' + file,\n",
        "           file)\n",
        "  print(\"Downloaded: {0}\".format(file))\n",
        "  uncompress_features_labels(file,\n",
        "                             'data/' + file.split('.zip')[0],\n",
        "                             'data/')\n",
        "  print(\"Extracted: {0}\".format(file))"
      ],
      "execution_count": 349,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloaded: infograph.zip\n",
            "Extracted: infograph.zip\n",
            "Downloaded: quickdraw.zip\n",
            "Extracted: quickdraw.zip\n",
            "Downloaded: real.zip\n",
            "Extracted: real.zip\n",
            "Downloaded: sketch.zip\n",
            "Extracted: sketch.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jygc0Hp9QAfh",
        "colab_type": "code",
        "outputId": "9f2cca86-6ca1-4dca-dac1-266a19efa1b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Project\n",
        "# Target images (labelled)\n",
        "download('http://csr.bu.edu/ftp/visda/2019/multi-source/groundtruth/clipart.zip', 'clipart.zip')\n",
        "print(\"Downloaded: clipart.zip\")\n",
        "uncompress_features_labels('clipart.zip', 'data/clipart', 'data/')\n",
        "print(\"Extracted: clipart.zip\")"
      ],
      "execution_count": 350,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloaded: clipart.zip\n",
            "Extracted: clipart.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gy9iTqgVQD6g",
        "colab_type": "code",
        "outputId": "95e03d44-438c-4847-d0a9-3478dfe010ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!mkdir label\n",
        "# Source labels\n",
        "for file in ['infograph', 'quickdraw', 'real', 'sketch']:\n",
        "  download('http://csr.bu.edu/ftp/visda/2019/multi-source/txt/' + file + '_train.txt',\n",
        "           'label/' + file + '_train.txt')\n",
        "  download('http://csr.bu.edu/ftp/visda/2019/multi-source/txt/' + file + '_test.txt',\n",
        "           'label/' + file + '_test.txt')\n",
        "  \n",
        "# Target labels (groundtruth)\n",
        "download('http://csr.bu.edu/ftp/visda/2019/multi-source/groundtruth/txt/clipart_test.txt',\n",
        "           'label/clipart_test.txt')"
      ],
      "execution_count": 351,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘label’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ppNPA0Ghc_x",
        "colab_type": "text"
      },
      "source": [
        "# Library\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDEXgNnahrpV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import os\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torch.utils.data as data\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.autograd import Function\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from PIL import Image, ImageColor\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8A70ryYZhxlu",
        "colab_type": "text"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgsRbyQjh0A3",
        "colab_type": "code",
        "outputId": "ab94544f-55a0-484d-e88a-8e24f82ec090",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Original\n",
        "source_dataset_name = 'source'\n",
        "target_dataset_name = 'target'\n",
        "model_root = 'models'\n",
        "!mkdir models\n",
        "cuda = False\n",
        "cudnn.benchmark = True\n",
        "lr = 1e-3\n",
        "batch_size = 32\n",
        "image_size = 28\n",
        "n_epoch = 5\n",
        "\n",
        "manual_seed = random.randint(1, 10000)\n",
        "random.seed(manual_seed)\n",
        "torch.manual_seed(manual_seed)\n"
      ],
      "execution_count": 353,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘models’: File exists\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f2fc20f4530>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 353
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQK658Xnh21k",
        "colab_type": "text"
      },
      "source": [
        "# Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GIxp0uBQRCB",
        "colab_type": "code",
        "outputId": "844c74ba-80f9-45c2-b9da-9dad75e9f951",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "num_labels = 10\n",
        "\n",
        "np.random.seed(647)\n",
        "\n",
        "# Randomly select labels\n",
        "\n",
        "selected_original_labels = random.sample(range(344), num_labels)\n",
        "\n",
        "selected_original_labels.sort()\n",
        "\n",
        "print(\"Selected labels: {0}\".format(selected_original_labels))\n",
        "\n",
        "# Mapping\n",
        "label_to_original_mapping = {}\n",
        "for i in range(0, num_labels):\n",
        "  label_to_original_mapping[i] = selected_original_labels[i]\n",
        "\n",
        "original_to_label_mapping = {v : k for k, v in label_to_original_mapping.items()}\n",
        "print(\"Original to label mapping: {0}\".format(original_to_label_mapping))\n",
        "print(\"Label to original mapping: {0}\".format(label_to_original_mapping))\n",
        "\n",
        "# Find English term\n",
        "original_to_english_mapping = {}\n",
        "for line in open(\"label/clipart_test.txt\"):\n",
        "  d = line.strip().split(' ')\n",
        "  l = int(d[1])\n",
        "  original_to_english_mapping[l] = d[0].split(\"/\")[1]\n",
        "\n",
        "print(\"Original to English mapping: {0}\".format(original_to_english_mapping))\n",
        "\n",
        "# Final label mapping\n",
        "labels = {}\n",
        "for i in range(0, num_labels):\n",
        "  labels[i] = original_to_english_mapping[label_to_original_mapping[i]]\n",
        "\n",
        "print(\"Labels: {0}\".format(labels))"
      ],
      "execution_count": 354,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selected labels: [1, 29, 82, 108, 123, 160, 179, 211, 213, 327]\n",
            "Original to label mapping: {1: 0, 29: 1, 82: 2, 108: 3, 123: 4, 160: 5, 179: 6, 211: 7, 213: 8, 327: 9}\n",
            "Label to original mapping: {0: 1, 1: 29, 2: 82, 3: 108, 4: 123, 5: 160, 6: 179, 7: 211, 8: 213, 9: 327}\n",
            "Original to English mapping: {0: 'aircraft_carrier', 1: 'airplane', 2: 'alarm_clock', 3: 'ambulance', 4: 'angel', 5: 'animal_migration', 6: 'ant', 7: 'anvil', 8: 'apple', 9: 'arm', 10: 'asparagus', 11: 'axe', 12: 'backpack', 13: 'banana', 14: 'bandage', 15: 'barn', 16: 'baseball', 17: 'baseball_bat', 18: 'basket', 19: 'basketball', 20: 'bat', 21: 'bathtub', 22: 'beach', 23: 'bear', 24: 'beard', 25: 'bed', 26: 'bee', 27: 'belt', 28: 'bench', 29: 'bicycle', 30: 'binoculars', 31: 'bird', 32: 'birthday_cake', 33: 'blackberry', 34: 'blueberry', 35: 'book', 36: 'boomerang', 37: 'bottlecap', 38: 'bowtie', 39: 'bracelet', 40: 'brain', 41: 'bread', 42: 'bridge', 43: 'broccoli', 44: 'broom', 45: 'bucket', 46: 'bulldozer', 47: 'bus', 48: 'bush', 49: 'butterfly', 50: 'cactus', 51: 'cake', 52: 'calculator', 53: 'calendar', 54: 'camel', 55: 'camera', 56: 'camouflage', 57: 'campfire', 58: 'candle', 59: 'cannon', 60: 'canoe', 61: 'car', 62: 'carrot', 63: 'castle', 64: 'cat', 65: 'ceiling_fan', 66: 'cello', 67: 'cell_phone', 68: 'chair', 69: 'chandelier', 70: 'church', 71: 'circle', 72: 'clarinet', 73: 'clock', 74: 'cloud', 75: 'coffee_cup', 76: 'compass', 77: 'computer', 78: 'cookie', 79: 'cooler', 80: 'couch', 81: 'cow', 82: 'crab', 83: 'crayon', 84: 'crocodile', 85: 'crown', 86: 'cruise_ship', 87: 'cup', 88: 'diamond', 89: 'dishwasher', 90: 'diving_board', 91: 'dog', 92: 'dolphin', 93: 'donut', 94: 'door', 95: 'dragon', 96: 'dresser', 97: 'drill', 98: 'drums', 99: 'duck', 100: 'dumbbell', 101: 'ear', 102: 'elbow', 103: 'elephant', 104: 'envelope', 105: 'eraser', 106: 'eye', 107: 'eyeglasses', 108: 'face', 109: 'fan', 110: 'feather', 111: 'fence', 112: 'finger', 113: 'fire_hydrant', 114: 'fireplace', 115: 'firetruck', 116: 'fish', 117: 'flamingo', 118: 'flashlight', 119: 'flip_flops', 120: 'floor_lamp', 121: 'flower', 122: 'flying_saucer', 123: 'foot', 124: 'fork', 125: 'frog', 126: 'frying_pan', 127: 'garden', 128: 'garden_hose', 129: 'giraffe', 130: 'goatee', 131: 'golf_club', 132: 'grapes', 133: 'grass', 134: 'guitar', 135: 'hamburger', 136: 'hammer', 137: 'hand', 138: 'harp', 139: 'hat', 140: 'headphones', 141: 'hedgehog', 142: 'helicopter', 143: 'helmet', 144: 'hexagon', 145: 'hockey_puck', 146: 'hockey_stick', 147: 'horse', 148: 'hospital', 149: 'hot_air_balloon', 150: 'hot_dog', 151: 'hot_tub', 152: 'hourglass', 153: 'house', 154: 'house_plant', 155: 'hurricane', 156: 'ice_cream', 157: 'jacket', 158: 'jail', 159: 'kangaroo', 160: 'key', 161: 'keyboard', 162: 'knee', 163: 'knife', 164: 'ladder', 165: 'lantern', 166: 'laptop', 167: 'leaf', 168: 'leg', 169: 'light_bulb', 170: 'lighter', 171: 'lighthouse', 172: 'lightning', 173: 'line', 174: 'lion', 175: 'lipstick', 176: 'lobster', 177: 'lollipop', 178: 'mailbox', 179: 'map', 180: 'marker', 181: 'matches', 182: 'megaphone', 183: 'mermaid', 184: 'microphone', 185: 'microwave', 186: 'monkey', 187: 'moon', 188: 'mosquito', 189: 'motorbike', 190: 'mountain', 191: 'mouse', 192: 'moustache', 193: 'mouth', 194: 'mug', 195: 'mushroom', 196: 'nail', 197: 'necklace', 198: 'nose', 199: 'ocean', 200: 'octagon', 201: 'octopus', 202: 'onion', 203: 'oven', 204: 'owl', 205: 'paintbrush', 206: 'paint_can', 207: 'palm_tree', 208: 'panda', 209: 'pants', 210: 'paper_clip', 211: 'parachute', 212: 'parrot', 213: 'passport', 214: 'peanut', 215: 'pear', 216: 'peas', 217: 'pencil', 218: 'penguin', 219: 'piano', 220: 'pickup_truck', 221: 'picture_frame', 222: 'pig', 223: 'pillow', 224: 'pineapple', 225: 'pizza', 226: 'pliers', 227: 'police_car', 228: 'pond', 229: 'pool', 230: 'popsicle', 231: 'postcard', 232: 'potato', 233: 'power_outlet', 234: 'purse', 235: 'rabbit', 236: 'raccoon', 237: 'radio', 238: 'rain', 239: 'rainbow', 240: 'rake', 241: 'remote_control', 242: 'rhinoceros', 243: 'rifle', 244: 'river', 245: 'roller_coaster', 246: 'rollerskates', 247: 'sailboat', 248: 'sandwich', 249: 'saw', 250: 'saxophone', 251: 'school_bus', 252: 'scissors', 253: 'scorpion', 254: 'screwdriver', 255: 'sea_turtle', 256: 'see_saw', 257: 'shark', 258: 'sheep', 259: 'shoe', 260: 'shorts', 261: 'shovel', 262: 'sink', 263: 'skateboard', 264: 'skull', 265: 'skyscraper', 266: 'sleeping_bag', 267: 'smiley_face', 268: 'snail', 269: 'snake', 270: 'snorkel', 271: 'snowflake', 272: 'snowman', 273: 'soccer_ball', 274: 'sock', 275: 'speedboat', 276: 'spider', 277: 'spoon', 278: 'spreadsheet', 279: 'square', 280: 'squiggle', 281: 'squirrel', 282: 'stairs', 283: 'star', 284: 'steak', 285: 'stereo', 286: 'stethoscope', 287: 'stitches', 288: 'stop_sign', 289: 'stove', 290: 'strawberry', 291: 'streetlight', 292: 'string_bean', 293: 'submarine', 294: 'suitcase', 295: 'sun', 296: 'swan', 297: 'sweater', 298: 'swing_set', 299: 'sword', 300: 'syringe', 301: 'table', 302: 'teapot', 303: 'teddy-bear', 304: 'telephone', 305: 'television', 306: 'tennis_racquet', 307: 'tent', 308: 'The_Eiffel_Tower', 309: 'The_Great_Wall_of_China', 310: 'The_Mona_Lisa', 311: 'tiger', 312: 'toaster', 313: 'toe', 314: 'toilet', 315: 'tooth', 316: 'toothbrush', 317: 'toothpaste', 318: 'tornado', 319: 'tractor', 320: 'traffic_light', 321: 'train', 322: 'tree', 323: 'triangle', 324: 'trombone', 325: 'truck', 326: 'trumpet', 327: 't-shirt', 328: 'umbrella', 329: 'underwear', 330: 'van', 331: 'vase', 332: 'violin', 333: 'washing_machine', 334: 'watermelon', 335: 'waterslide', 336: 'whale', 337: 'wheel', 338: 'windmill', 339: 'wine_bottle', 340: 'wine_glass', 341: 'wristwatch', 342: 'yoga', 343: 'zebra', 344: 'zigzag'}\n",
            "Labels: {0: 'airplane', 1: 'bicycle', 2: 'crab', 3: 'face', 4: 'foot', 5: 'key', 6: 'map', 7: 'parachute', 8: 'passport', 9: 't-shirt'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_E12hYvaQTa4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###### LIST LOADER #######\n",
        "\n",
        "def default_loader(path):\n",
        "    \"\"\"Default loader\n",
        "    \"\"\"\n",
        "    return Image.open(path).convert('RGB')\n",
        "\n",
        "def collect_images(img_dir, labels):\n",
        "  \"\"\"Return a list of (image path, label)\n",
        "\n",
        "  Parameters:\n",
        "  img_dir (String) : the directory containing the images\n",
        "  labels (List[String]) : a list of labels (merged multiple sources together)\n",
        "\n",
        "  Returns:\n",
        "  List[(String, String)]\n",
        "  \"\"\"\n",
        "  images = []\n",
        "  indices = {}\n",
        "  pos = 0\n",
        "  for line in labels:\n",
        "    data = line.strip().split(' ')\n",
        "    path = os.path.join(img_dir, data[0])\n",
        "    original_label = int(data[1])\n",
        "    # Among the 10 labels selected\n",
        "    if original_label in selected_original_labels:\n",
        "      label = original_to_label_mapping[original_label]\n",
        "      item = (path, label)\n",
        "      images.append(item)\n",
        "      if label not in indices.keys():\n",
        "        indices[label] = [pos]\n",
        "      else:\n",
        "        indices[label].append(pos)\n",
        "      pos += 1\n",
        "  return images, indices\n",
        "\n",
        "class MyDataset(data.Dataset):\n",
        "    \"\"\" Custom class for loading image list\n",
        "    \"\"\"\n",
        "    def __init__(self, img_dir, labels, transform=None, loader=default_loader):\n",
        "        imgs, indices = collect_images(img_dir, labels)\n",
        "        self.img_dir = img_dir\n",
        "        self.imgs = imgs\n",
        "        self.indices = indices\n",
        "        self.num_imgs = len(imgs)\n",
        "        self.transform = transform\n",
        "        self.loader = loader\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        path, label = self.imgs[index]\n",
        "        img = self.loader(path)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "            \n",
        "        return img, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "\n",
        "    def get_random_sample_index(self, label, n=1):\n",
        "      return np.random.choice(self.indices[label], n)[0]\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWOCTJ7SQWiK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###### IMAGE LOADER #######\n",
        "\n",
        "def make_data_set(img_dir, label_dir, domain_list, transforms, train_or_test):\n",
        "  labels = []\n",
        "  for domain in domain_list:\n",
        "    # E.g. \"label/infograph_test.txt\"\n",
        "    label_file = label_dir + domain + '_' + train_or_test + '.txt'\n",
        "    for line in open(label_file):\n",
        "      labels.append(line)\n",
        "  return MyDataset(img_dir, labels, transforms)\n",
        "\n",
        "def make_data_loader(dataset, train_or_test):\n",
        "  if (train_or_test == 'train'):\n",
        "    return data.DataLoader(dataset, batch_size=4,\n",
        "                           shuffle=True, num_workers=4)\n",
        "  else:\n",
        "    return data.DataLoader(dataset, batch_size=4,\n",
        "                           shuffle=True, num_workers=4)\n",
        "    \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXM6dFuzQY4K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean = np.array([0.485, 0.456, 0.406])\n",
        "std = np.array([0.229, 0.224, 0.225])\n",
        "\n",
        "def tensor_to_PIL(img, mean, std):\n",
        "  img = img.numpy().transpose((1, 2, 0))\n",
        "  img = img * std + mean\n",
        "  img = np.clip(img, 0, 1)\n",
        "  return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7_clv5Uh5pk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Original\n",
        "# class GetLoader(data.Dataset):\n",
        "#     def __init__(self, data_root, data_list, transform=None):\n",
        "#         self.root = data_root\n",
        "#         self.transform = transform\n",
        "\n",
        "#         f = open(data_list, 'r')\n",
        "#         data_list = f.readlines()\n",
        "#         f.close()\n",
        "\n",
        "#         self.n_data = len(data_list)\n",
        "\n",
        "#         self.img_paths = []\n",
        "#         self.img_labels = []\n",
        "\n",
        "#         for data in data_list:\n",
        "#             self.img_paths.append(data[:-3])\n",
        "#             self.img_labels.append(data[-2])\n",
        "\n",
        "#     def __getitem__(self, item):\n",
        "#         img_paths, labels = self.img_paths[item], self.img_labels[item]\n",
        "#         imgs = Image.open(os.path.join(self.root, img_paths)).convert('RGB')\n",
        "\n",
        "#         if self.transform is not None:\n",
        "#             imgs = self.transform(imgs)\n",
        "#             labels = int(labels)\n",
        "\n",
        "#         return imgs, labels\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return self.n_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOa9VlCzh8xW",
        "colab_type": "text"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ki-9WhXjh_Vk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Original\n",
        "# img_transform_source = transforms.Compose([\n",
        "#     transforms.Resize(image_size),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize(mean=(0.1307,), std=(0.3081,))\n",
        "# ])\n",
        "\n",
        "# img_transform_target = transforms.Compose([\n",
        "#     transforms.Resize(image_size),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
        "# ])\n",
        "\n",
        "# dataset_source = datasets.MNIST(\n",
        "#     root='dataset',\n",
        "#     train=True,\n",
        "#     transform=img_transform_source,\n",
        "#     download=True\n",
        "# )\n",
        "\n",
        "# dataloader_source = torch.utils.data.DataLoader(\n",
        "#     dataset=dataset_source,\n",
        "#     batch_size=batch_size,\n",
        "#     shuffle=True,\n",
        "#     num_workers=0)\n",
        "\n",
        "# train_list = os.path.join(target_image_root, 'mnist_m_train_labels.txt')\n",
        "\n",
        "# dataset_target = GetLoader(\n",
        "#     data_root=os.path.join(target_image_root, 'mnist_m_train'),\n",
        "#     data_list=train_list,\n",
        "#     transform=img_transform_target\n",
        "# )\n",
        "\n",
        "# dataloader_target = torch.utils.data.DataLoader(\n",
        "#     dataset=dataset_target,\n",
        "#     batch_size=batch_size,\n",
        "#     shuffle=True,\n",
        "#     num_workers=0)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KObFunUmQcIn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "home_dir = ''\n",
        "img_dir = home_dir + 'data/'\n",
        "label_dir = home_dir + 'label/'\n",
        "# source = ['quickdraw', 'real', 'sketch']\n",
        "# target = ['clipart']\n",
        "source = ['real', 'sketch']\n",
        "target = ['clipart']\n",
        "\n",
        "\n",
        "train_transforms = transforms.Compose([transforms.Resize([28, 28]),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                            [0.229, 0.224, 0.225])])\n",
        "\n",
        "test_transforms = transforms.Compose([transforms.Resize([28, 28]),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                           [0.229, 0.224, 0.225])])\n",
        "\n",
        "target_transforms = transforms.Compose([transforms.Resize([28, 28]),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                             [0.229, 0.224, 0.225])])\n",
        "\n",
        "dataset_source = make_data_set(img_dir, label_dir, source, train_transforms, 'train')\n",
        "dataloader_source = make_data_loader(dataset_source, 'train')\n",
        "#source_test_dataset = make_data_set(img_dir, label_dir, source, test_transforms, 'test')\n",
        "#source_test_dataloader = make_data_loader(source_test_dataset, 'test')\n",
        "dataset_target = make_data_set(img_dir, label_dir, target, target_transforms, 'test')\n",
        "dataloader_target = make_data_loader(dataset_target, 'test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OboJfN1FQh3u",
        "colab_type": "code",
        "outputId": "6e7376e2-cb0c-40f3-bd2a-2d89e1c0d622",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(\"Source train dataset size: {0}\".format(len(dataset_source)))\n",
        "#print(\"Source test dataset size: {0}\".format(len(source_test_dataset)))\n",
        "print(\"Target dataset size: {0}\".format(len(dataset_target)))"
      ],
      "execution_count": 359,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Source train dataset size: 5250\n",
            "Target dataset size: 214\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WMklQwliCWt",
        "colab_type": "text"
      },
      "source": [
        "# ReverseLayerF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egdLgeoSiHJG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class ReverseLayerF(Function):\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, alpha):\n",
        "        ctx.alpha = alpha\n",
        "\n",
        "        return x.view_as(x)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        output = grad_output.neg() * ctx.alpha\n",
        "\n",
        "        return output, None\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3liWymc3iJaJ",
        "colab_type": "text"
      },
      "source": [
        "# Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ejklo1e2iMEF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNNModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.feature = nn.Sequential()\n",
        "        self.feature.add_module('f_conv1', nn.Conv2d(3, 64, kernel_size=5))\n",
        "        self.feature.add_module('f_bn1', nn.BatchNorm2d(64))\n",
        "        self.feature.add_module('f_pool1', nn.MaxPool2d(2))\n",
        "        self.feature.add_module('f_relu1', nn.ReLU(True))\n",
        "        self.feature.add_module('f_conv2', nn.Conv2d(64, 50, kernel_size=5))\n",
        "        self.feature.add_module('f_bn2', nn.BatchNorm2d(50))\n",
        "        self.feature.add_module('f_drop1', nn.Dropout2d())\n",
        "        self.feature.add_module('f_pool2', nn.MaxPool2d(2))\n",
        "        self.feature.add_module('f_relu2', nn.ReLU(True))\n",
        "\n",
        "        self.class_classifier = nn.Sequential()\n",
        "        self.class_classifier.add_module('c_fc1', nn.Linear(50 * 4 * 4, 100))\n",
        "        self.class_classifier.add_module('c_bn1', nn.BatchNorm1d(100))\n",
        "        self.class_classifier.add_module('c_relu1', nn.ReLU(True))\n",
        "        self.class_classifier.add_module('c_drop1', nn.Dropout2d())\n",
        "        self.class_classifier.add_module('c_fc2', nn.Linear(100, 100))\n",
        "        self.class_classifier.add_module('c_bn2', nn.BatchNorm1d(100))\n",
        "        self.class_classifier.add_module('c_relu2', nn.ReLU(True))\n",
        "        self.class_classifier.add_module('c_fc3', nn.Linear(100, 10))\n",
        "        self.class_classifier.add_module('c_softmax', nn.LogSoftmax())\n",
        "\n",
        "        self.domain_classifier = nn.Sequential()\n",
        "        self.domain_classifier.add_module('d_fc1', nn.Linear(50 * 4 * 4, 100))\n",
        "        self.domain_classifier.add_module('d_bn1', nn.BatchNorm1d(100))\n",
        "        self.domain_classifier.add_module('d_relu1', nn.ReLU(True))\n",
        "        self.domain_classifier.add_module('d_fc2', nn.Linear(100, 2))\n",
        "        self.domain_classifier.add_module('d_softmax', nn.LogSoftmax(dim=1))\n",
        "\n",
        "    def forward(self, input_data, alpha):\n",
        "        input_data = input_data.expand(input_data.data.shape[0], 3, 28, 28)\n",
        "        feature = self.feature(input_data)\n",
        "        feature = feature.view(-1, 50 * 4 * 4)\n",
        "        reverse_feature = ReverseLayerF.apply(feature, alpha)\n",
        "        class_output = self.class_classifier(feature)\n",
        "        domain_output = self.domain_classifier(reverse_feature)\n",
        "\n",
        "        return class_output, domain_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EST0pdwtiO1R",
        "colab_type": "text"
      },
      "source": [
        "# Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gUhQTfViR2a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "my_net = CNNModel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6h8UEzcLiVFt",
        "colab_type": "text"
      },
      "source": [
        "# Setup Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AF94ww5xiY76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(my_net.parameters(), lr=lr)\n",
        "\n",
        "loss_class = torch.nn.NLLLoss()\n",
        "loss_domain = torch.nn.NLLLoss()\n",
        "\n",
        "if cuda:\n",
        "    my_net = my_net.cuda()\n",
        "    loss_class = loss_class.cuda()\n",
        "    loss_domain = loss_domain.cuda()\n",
        "\n",
        "for p in my_net.parameters():\n",
        "    p.requires_grad = True\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bujjyq6IieDo",
        "colab_type": "text"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbzrF4SWigkK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def test(dataset_name, epoch):\n",
        "    assert dataset_name in ['source', 'target']\n",
        "\n",
        "    model_root = 'models'\n",
        "   #image_root = os.path.join('dataset', dataset_name)\n",
        "\n",
        "    cuda = False\n",
        "    cudnn.benchmark = True\n",
        "    batch_size = 32\n",
        "    image_size = 28\n",
        "    alpha = 0\n",
        "\n",
        "    \"\"\"load data\"\"\"\n",
        "\n",
        "    home_dir = ''\n",
        "    img_dir = home_dir + 'data/'\n",
        "    label_dir = home_dir + 'label/'\n",
        "    source = ['quickdraw', 'real', 'sketch']\n",
        "    target = ['clipart']\n",
        "    \n",
        "\n",
        "    train_transforms = transforms.Compose([transforms.Resize([28, 28]),\n",
        "                                           transforms.ToTensor(),\n",
        "                                           transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                                [0.229, 0.224, 0.225])])\n",
        "\n",
        "    test_transforms = transforms.Compose([transforms.Resize([28, 28]),\n",
        "                                          transforms.ToTensor(),\n",
        "                                          transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                               [0.229, 0.224, 0.225])])\n",
        "\n",
        "    target_transforms = transforms.Compose([transforms.Resize([28, 28]),\n",
        "                                            transforms.ToTensor(),\n",
        "                                            transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                                 [0.229, 0.224, 0.225])])\n",
        "\n",
        "    dataset_source = make_data_set(img_dir, label_dir, source, train_transforms, 'train')\n",
        "    dataloader_source = make_data_loader(dataset_source, 'train')\n",
        "    #source_test_dataset = make_data_set(img_dir, label_dir, source, test_transforms, 'test')\n",
        "    #source_test_dataloader = make_data_loader(source_test_dataset, 'test')\n",
        "    dataset_target = make_data_set(img_dir, label_dir, target, target_transforms, 'test')\n",
        "    dataloader_target = make_data_loader(dataset_target, 'test')\n",
        "\n",
        "    if dataset_name == 'source':\n",
        "        dataset_source = make_data_set(img_dir, label_dir, source, train_transforms, 'train')\n",
        "        dataloader = make_data_loader(dataset_source, 'train')\n",
        "    else:\n",
        "        dataset_target = make_data_set(img_dir, label_dir, target, target_transforms, 'test')\n",
        "        dataloader = make_data_loader(dataset_target, 'test')\n",
        "\n",
        "\n",
        "    \"\"\" training \"\"\"\n",
        "\n",
        "    model = CNNModel()\n",
        "    checkpoint = torch.load('./models/mnist_mnistm_model_epoch_' + str(epoch) + '.pth')\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "  \n",
        "  \n",
        "  \n",
        "    my_net = model.eval()\n",
        "\n",
        "    if cuda:\n",
        "        my_net = my_net.cuda()\n",
        "\n",
        "    len_dataloader = len(dataloader)\n",
        "    data_target_iter = iter(dataloader)\n",
        "\n",
        "    i = 0\n",
        "    n_total = 0\n",
        "    n_correct = 0\n",
        "\n",
        "    while i < len_dataloader:\n",
        "\n",
        "        # test model using target data\n",
        "        data_target = data_target_iter.next()\n",
        "        t_img, t_label = data_target\n",
        "\n",
        "        batch_size = len(t_label)\n",
        "\n",
        "        input_img = torch.FloatTensor(batch_size, 3, image_size, image_size)\n",
        "        class_label = torch.LongTensor(batch_size)\n",
        "\n",
        "        if cuda:\n",
        "            t_img = t_img.cuda()\n",
        "            t_label = t_label.cuda()\n",
        "            input_img = input_img.cuda()\n",
        "            class_label = class_label.cuda()\n",
        "\n",
        "        input_img.resize_as_(t_img).copy_(t_img)\n",
        "        class_label.resize_as_(t_label).copy_(t_label)\n",
        "\n",
        "        class_output, _ = my_net(input_data=input_img, alpha=alpha)\n",
        "        pred = class_output.data.max(1, keepdim=True)[1]\n",
        "        n_correct += pred.eq(class_label.data.view_as(pred)).cpu().sum()\n",
        "        n_total += batch_size\n",
        "\n",
        "        i += 1\n",
        "\n",
        "    accu = n_correct.data.numpy() * 1.0 / n_total\n",
        "    \n",
        "    print ('    epoch: %d, accuracy of the %s dataset: %f' % (epoch, dataset_name, accu))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6l8S1sgilmu",
        "colab_type": "text"
      },
      "source": [
        "# Training & Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGfsYgHCiozE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "cf2a4335-363d-4f77-a7a2-caa28f6f1a42"
      },
      "source": [
        "\n",
        "for epoch in range(n_epoch):\n",
        "\n",
        "    len_dataloader = min(len(dataloader_source), len(dataloader_target))\n",
        "    data_source_iter = iter(dataloader_source)\n",
        "    data_target_iter = iter(dataloader_target)\n",
        "\n",
        "    i = 0\n",
        "    while i < len_dataloader:\n",
        "\n",
        "        p = float(i + epoch * len_dataloader) / n_epoch / len_dataloader\n",
        "        alpha = 2. / (1. + np.exp(-10 * p)) - 1\n",
        "\n",
        "        # training model using source data\n",
        "        data_source = data_source_iter.next()\n",
        "        s_img, s_label = data_source\n",
        "\n",
        "        my_net.zero_grad()\n",
        "        batch_size = len(s_label)\n",
        "\n",
        "        input_img = torch.FloatTensor(batch_size, 3, image_size, image_size)\n",
        "        class_label = torch.LongTensor(batch_size)\n",
        "        domain_label = torch.zeros(batch_size)\n",
        "        domain_label = domain_label.long()\n",
        "\n",
        "        if cuda:\n",
        "            s_img = s_img.cuda()\n",
        "            s_label = s_label.cuda()\n",
        "            input_img = input_img.cuda()\n",
        "            class_label = class_label.cuda()\n",
        "            domain_label = domain_label.cuda()\n",
        "\n",
        "        input_img.resize_as_(s_img).copy_(s_img)\n",
        "        class_label.resize_as_(s_label).copy_(s_label)\n",
        "\n",
        "        class_output, domain_output = my_net(input_data=input_img, alpha=alpha)\n",
        "        err_s_label = loss_class(class_output, class_label)\n",
        "        err_s_domain = loss_domain(domain_output, domain_label)\n",
        "\n",
        "        # training model using target data\n",
        "        data_target = data_target_iter.next()\n",
        "        t_img, _ = data_target\n",
        "\n",
        "        batch_size = len(t_img)\n",
        "\n",
        "        input_img = torch.FloatTensor(batch_size, 3, image_size, image_size)\n",
        "        domain_label = torch.ones(batch_size)\n",
        "        domain_label = domain_label.long()\n",
        "\n",
        "        if cuda:\n",
        "            t_img = t_img.cuda()\n",
        "            input_img = input_img.cuda()\n",
        "            domain_label = domain_label.cuda()\n",
        "\n",
        "        input_img.resize_as_(t_img).copy_(t_img)\n",
        "\n",
        "        _, domain_output = my_net(input_data=input_img, alpha=alpha)\n",
        "        err_t_domain = loss_domain(domain_output, domain_label)\n",
        "        err = err_t_domain + err_s_domain + err_s_label\n",
        "        err.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        i += 1\n",
        "\n",
        "        print (\"\\r\",'epoch: %d, [iter: %d / all %d], err_s_label: %f, err_s_domain: %f, err_t_domain: %f' \\\n",
        "              % (epoch, i, len_dataloader, err_s_label.data.cpu().numpy(),\n",
        "                 err_s_domain.data.cpu().numpy(), err_t_domain.data.cpu().item()),end=\"\")\n",
        "    print(' ')\n",
        "    \n",
        "    torch.save({'state_dict': my_net.state_dict()}, '{0}/mnist_mnistm_model_epoch_{1}.pth'.format(model_root, epoch))\n",
        "\n",
        "\n",
        "    test(source_dataset_name, epoch)\n",
        "    test(target_dataset_name, epoch)\n",
        "\n",
        "print('done')\n"
      ],
      "execution_count": 365,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " epoch: 0, [iter: 54 / all 54], err_s_label: 2.605547, err_s_domain: 0.717916, err_t_domain: 0.682170 \n",
            "    epoch: 0, accuracy of the source dataset: 0.112343\n",
            "    epoch: 0, accuracy of the target dataset: 0.074766\n",
            " epoch: 1, [iter: 54 / all 54], err_s_label: 2.538148, err_s_domain: 0.707359, err_t_domain: 0.678090 \n",
            "    epoch: 1, accuracy of the source dataset: 0.184114\n",
            "    epoch: 1, accuracy of the target dataset: 0.172897\n",
            " epoch: 2, [iter: 54 / all 54], err_s_label: 2.171398, err_s_domain: 0.700501, err_t_domain: 0.691629 \n",
            "    epoch: 2, accuracy of the source dataset: 0.175429\n",
            "    epoch: 2, accuracy of the target dataset: 0.210280\n",
            " epoch: 3, [iter: 54 / all 54], err_s_label: 1.976601, err_s_domain: 0.699192, err_t_domain: 0.724955 \n",
            "    epoch: 3, accuracy of the source dataset: 0.158514\n",
            "    epoch: 3, accuracy of the target dataset: 0.144860\n",
            " epoch: 4, [iter: 54 / all 54], err_s_label: 2.642530, err_s_domain: 0.682148, err_t_domain: 0.696405 \n",
            "    epoch: 4, accuracy of the source dataset: 0.171543\n",
            "    epoch: 4, accuracy of the target dataset: 0.196262\n",
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}